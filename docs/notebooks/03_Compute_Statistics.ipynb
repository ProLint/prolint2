{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Introduction to the ProLint Contact Interface"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "`Note`: This notebook is rather lengthy and discusses the entire ProLint interface. There are different ways of doing things, and plenty of ways to extend the available functionality. It may make sense to separate this into multiple notebooks, for beginners and advanced users. "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/Users/danielramirez/mambaforge/envs/prolint2/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
                        "  from .autonotebook import tqdm as notebook_tqdm\n"
                    ]
                }
            ],
            "source": [
                "from typing import List, Iterable\n",
                "import numpy as np\n",
                "from prolint2 import Universe\n",
                "from prolint2.sampledata import GIRKDataSample\n",
                "GIRK = GIRKDataSample()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [],
            "source": [
                "ts = Universe(GIRK.coordinates, GIRK.trajectory)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "100%|██████████| 13/13 [00:00<00:00, 195.66it/s]\n"
                    ]
                }
            ],
            "source": [
                "contacts = ts.compute_contacts(cutoff=7)"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Non-formatted contact output"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [],
            "source": [
                "# These are triply nested dictionaries containing all contact information\n",
                "# contacts.contact_frames, contacts.contacts"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Computing different metrics"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [],
            "source": [
                "from prolint2.metrics.metrics import Metric, MeanMetric, SumMetric, MaxMetric"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### Computing contact metrics is very easy"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [],
            "source": [
                "mean_instance = MeanMetric() # create an instance of the MeanMetric class\n",
                "metric_instance = Metric(contacts, mean_instance) # feed the contacts and the above instance to the Metric class\n",
                "mean_contacts = metric_instance.compute() # compute the metric"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [],
            "source": [
                "sum_instance = SumMetric()\n",
                "metric_instance = Metric(contacts, sum_instance)\n",
                "sum_contacts = metric_instance.compute()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "defaultdict(dict,\n",
                            "            {'POPE': {'SumMetric': 0.25},\n",
                            "             'POPS': {'SumMetric': 0.41666666666666663}})"
                        ]
                    },
                    "execution_count": 8,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "sum_contacts[14]"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### Defining a new metric class is also very easy"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [],
            "source": [
                "from prolint2.metrics.base import BaseMetric # import the base class\n",
                "\n",
                "# contact_array are all the contacts a single residue forms for each lipid. ProLint will call your function `compute_metric` with this array as an argument\n",
                "# For example, if you have 10 residues and 1 lipid, ProLint will call your function 10 times, each time with a contact_array consisting of all \n",
                "# the contacts that residue forms with the lipid during the trajectory.\n",
                "\n",
                "# `compute_metric`` should take an iterable (e.g. list, numpy array) as input and return a single value\n",
                "\n",
                "class ScaleAndMeanMetric(BaseMetric):\n",
                "    \"\"\" A metric that computes the mean of the contacts after scaling them by 2. \"\"\"\n",
                "    name: str = 'scale'\n",
                "    def compute_metric(self, contact_array: Iterable) -> float:\n",
                "        return np.mean(contact_array) * 2\n",
                "\n",
                "class RandomWeightedMeanMetric(BaseMetric):\n",
                "    \"\"\" A metric that computes the weighted mean of the contacts using random weights. \"\"\"\n",
                "    name: str = 'weighted_mean'\n",
                "    def compute_metric(self, contact_array: Iterable) -> float:\n",
                "        return np.average(contact_array, weights=np.random.rand(len(contact_array)))\n",
                "    \n",
                "scale_and_mean_instance = Metric(contacts, ScaleAndMeanMetric())\n",
                "scale_and_mean_contacts = scale_and_mean_instance.compute()\n",
                "\n",
                "weighted_mean_instance = Metric(contacts, RandomWeightedMeanMetric())\n",
                "weighted_mean_contacts = weighted_mean_instance.compute()\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### We also provide a class that you can use directly with your own metric function"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [],
            "source": [
                "from prolint2.metrics.metrics import UserDefinedMetric\n",
                "\n",
                "# Defining a new metric is as simple as defining a function that takes an iterable as input and returns a single value\n",
                "def custom_user_function(contact_array: Iterable) -> float:\n",
                "    \"\"\" A custom metric that computes the mean of the contacts after scaling them by 10. \"\"\"\n",
                "    return np.mean(contact_array) * 10\n",
                "\n",
                "# Give your function to the UserDefinedMetric class and that's it!\n",
                "user_metric_instance = UserDefinedMetric(custom_user_function)\n",
                "user_metric = Metric(contacts, user_metric_instance)\n",
                "user_metric_contacts = user_metric.compute()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### You can also choose to append results to the metric ouput by telling `Metric` to not clear previous results"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {},
            "outputs": [],
            "source": [
                "metric_instance = Metric(contacts, MeanMetric()) # by default clear is True, so we clear any existing metrics\n",
                "contacts_out = metric_instance.compute() # populate the metric column\n",
                "\n",
                "metric_instance = Metric(contacts, SumMetric(), clear=False) # set clear to False to keep the existing metrics\n",
                "contacts_out = metric_instance.compute() # populate the metric column\n",
                "\n",
                "metric_instance = Metric(contacts, MaxMetric(), clear=False) # set clear to False to keep the existing metrics\n",
                "contacts_out = metric_instance.compute() # populate the metric column"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### You can also specify a list of metrics to compute at once"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "metadata": {},
            "outputs": [],
            "source": [
                "metric_instances_list = [MeanMetric(), SumMetric(), MaxMetric()]\n",
                "metric_instance = Metric(contacts, metric_instances_list) # clear is True by default so we clear any existing metrics\n",
                "contacts_out = metric_instance.compute() # populate the metric columns"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### You can choose from different types of output formats"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "metadata": {},
            "outputs": [],
            "source": [
                "# DefaultOutputFormat is the default output format if no other format is specified\n",
                "from prolint2.metrics.formatters import DefaultOutputFormat, SingleOutputFormat, CustomOutputFormat, ProLintDashboardOutputFormat"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "metadata": {},
            "outputs": [],
            "source": [
                "metric_instances_list = [MeanMetric(), SumMetric(), MaxMetric()]\n",
                "metric_instance = Metric(contacts, metric_instances_list, output_format=CustomOutputFormat()) # gives a list of metrics matching the order of the metric_instances_list\n",
                "contacts_out = metric_instance.compute() # populate the metric columns"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ProLintDashboardOutputFormat is used by the ProLint Dashboard and it requires the residue names and residue ids\n",
                "input_dict = {\n",
                "    'residue_names': ts.query.residues.resnames, \n",
                "    'residue_ids': ts.query.residues.resids\n",
                "}\n",
                "\n",
                "metric_instances_list = MeanMetric() # you can pass more than one metric instance and it works, but the format is not intended for that\n",
                "metric_instance = Metric(\n",
                "    contacts, \n",
                "    metric_instances_list, \n",
                "    output_format=ProLintDashboardOutputFormat(**input_dict)\n",
                ")\n",
                "\n",
                "contacts_out = metric_instance.compute()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 16,
            "metadata": {},
            "outputs": [],
            "source": [
                "# If you care only for one metric, you can use the SingleOutputFormat\n",
                "metric_instances_list = MeanMetric() \n",
                "metric_instance = Metric(\n",
                "    contacts,\n",
                "    metric_instances_list,\n",
                "    output_format=SingleOutputFormat()\n",
                ")\n",
                "\n",
                "contacts_out = metric_instance.compute()"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### The `create_metric` function is a convenience function that creates a Metric instance and computes the metric in one simple step"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 17,
            "metadata": {},
            "outputs": [],
            "source": [
                "from prolint2.metrics.metrics import create_metric"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 18,
            "metadata": {},
            "outputs": [],
            "source": [
                "registry = ts.registry # get the registry of supported metrics"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 19,
            "metadata": {},
            "outputs": [],
            "source": [
                "metric_instance = create_metric(\n",
                "    contacts, \n",
                "    metrics=['mean', 'sum', 'max'], \n",
                "    metric_registry=registry, \n",
                "    output_format='default' # default, single, custom, dashboard\n",
                ")\n",
                "\n",
                "contacts_out = metric_instance.compute()\n"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### Using `create_metric` with a custom function"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 20,
            "metadata": {},
            "outputs": [],
            "source": [
                "def custom_function(contact_array: Iterable) -> float:\n",
                "    return np.mean(contact_array) * 10"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 21,
            "metadata": {},
            "outputs": [],
            "source": [
                "metric_instance = create_metric(\n",
                "    contacts, \n",
                "    metrics=['custom'], # we want to use our custom function\n",
                "    custom_function=custom_function, # pass the custom function\n",
                "    metric_registry=registry, \n",
                "    output_format='default'\n",
                ")\n",
                "\n",
                "contacts_out = metric_instance.compute()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### Adding our Metric classes to the registry"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 22,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "['max', 'mean', 'sum', 'custom']"
                        ]
                    },
                    "execution_count": 22,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "# These are all the functions currently in the registry\n",
                "registry.get_registered_names()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 23,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Let's add the `ScaleAndMeanMetric` metric we defined earlier to the registry\n",
                "# we provide the name of the metric and the class\n",
                "registry.register('scaled_mean', ScaleAndMeanMetric)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 24,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "['max', 'mean', 'sum', 'custom', 'scaled_mean']"
                        ]
                    },
                    "execution_count": 24,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "# Show all functions in the registry again to see that the new metric is there\n",
                "registry.get_registered_names()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 25,
            "metadata": {},
            "outputs": [],
            "source": [
                "metric_instance = create_metric(\n",
                "    contacts, \n",
                "    metrics=['scaled_mean', 'max', 'mean'], # we can now use the new metric by referring to it by name\n",
                "    metric_registry=registry, \n",
                "    output_format='default'\n",
                ")\n",
                "\n",
                "contacts_out = metric_instance.compute()\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### You can also convert between the different output formats"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 26,
            "metadata": {},
            "outputs": [],
            "source": [
                "from prolint2.metrics.converters import DefaultToSingleConverter, CustomToSingleConverter"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 27,
            "metadata": {},
            "outputs": [],
            "source": [
                "# We can convert from the default output format to the single output format\n",
                "metric_instance = create_metric(\n",
                "    contacts, \n",
                "    metrics=['scaled_mean', 'max', 'mean'], # we can now use the new metric by referring to it by name\n",
                "    metric_registry=registry, \n",
                "    output_format='default'\n",
                ")\n",
                "contacts_out = metric_instance.compute()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 28,
            "metadata": {},
            "outputs": [],
            "source": [
                "# we can also get other metrics we've computed\n",
                "extract_single_metric = DefaultToSingleConverter(contacts_out, 'scaled_mean', registry).convert().get_result() "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 29,
            "metadata": {},
            "outputs": [],
            "source": [
                "# We can convert from the custom output format to the single output format\n",
                "metric_instance = create_metric(\n",
                "    contacts, \n",
                "    metrics=['scaled_mean', 'max', 'mean'], # we can now use the new metric by referring to it by name\n",
                "    metric_registry=registry, \n",
                "    output_format='custom'\n",
                ")\n",
                "contacts_out = metric_instance.compute()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 30,
            "metadata": {},
            "outputs": [],
            "source": [
                "# we have to specify the index of the metric we want to extract\n",
                "extract_single_metric = CustomToSingleConverter(contacts_out, 0, registry).convert().get_result()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "ufcc-dev",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.16"
        },
        "orig_nbformat": 4
    },
    "nbformat": 4,
    "nbformat_minor": 2
}